Ensembling Procedure
========================================================
author: 
date: 

Ensemble of Classifcation Algorithms
========================================================

![Ensemble Procedure](ensemble.png)

The Problem
========================================================

__Individual algorithms perform better/worse on certain types of prompt/rubric pairs__

One Solution:
 - Manually select which algorithms to use in the ensemble
 
The Problem with the Solution
========================================================

Good, except for:
 - Manual selection challenging and time consuming
 - Even lesser algorithms contribute when used in aggregate
 
Another Solution
========================================================
 
__A Smarter Ensembling Proceedure__
 
Let the system select (or bettering yet assign weights to) the individual classifiers during the training of a scoring model
 
Current Solution: Simple Voting
========================================================

![Ensemble Procedure](ensemble.png)

One Better: Leverage Scoring Probability
========================================================

![Ensemble Procedure](ensemble2.png)

First Approach: Probabilty Weighted Voting
========================================================

__Select the score with the highest aggregate probability__

Example: 3 Algorithms with positive/negative classification

```{r,echo=FALSE}
aa<- c(0.52,0.55,0.3)
bb <- 1-aa
a <- rbind(c(aa,sum(aa)),c(bb,(sum(bb))))
colnames(a) <- c("Algorithm 1","Algorithm 2","Algorithm 3","Total")
rownames(a) <- c("Postive","Negative")
kable(a)
```

Probabilty Weighted Voting
========================================================
__Select the score with the highest aggregate probability__

_Pros_
 - Fast/Cheap/Simple
 - Leverages self reported probabilities
 
_Cons_
 - Leverages self reported probabilites

A Second Approach: Ensembling Classifier
========================================================
__Fit a secondary classifier that uses probabilites as features__

A secondary classifier would:
 - Select which algorithms to use as input
 - Weight the input classifiers based on predictive power
 - Utalize probabilities in a more sofisticated manner
 
A Second Approach: Ensembling Classifier
========================================================
__Fit a secondary classifier that uses probabilites as features__

Caveats
 - More computationally intense
 - Reduce the amount of data availible to primary classifiers
 
More Specifically: Penalized Logistic Regression
========================================================

__Penalized Logistic Regression__
 - Logistic regression with weighting
 - Designed to minimized overfitting with lots of features
 - Effectively limits influence of features with low predictive power 

Limitations of Current System
========================================================
__In the current implementation each individual a score and an associated probability__

Example: Data returned by a single classifier for a 3 level holistic rubric
```{r,echo=FALSE}
tabOut <- data.frame(Score=c(1,3,2,1,1),Probability=c(0.95,0.83,0.43,0.67,0.87))
kable(tabOut)

```

Limitations of Current System
========================================================
__In the current implementation each individual a score and an associated probability__

To construct a complete feature set for this example we would need probabilites
```{r,echo=FALSE}
aa <- c(0.95,0.33,0.13,0.07,0.67)
bb <- c(0.02,0.40,0.72,0.05,0.21)
cc <- 1-(aa+bb)
tabOut2 <- data.frame(aa,bb,cc)
colnames(tabOut2) <- c("Bin 1","Bin 2","Bin 3")
kable(tabOut2)
```

Limitations of Current System
========================================================

__*Thus* within current framework either weighted voting or PLR ensembling may only be performed with on analytic rubrics with positive/negtive coded bins__

Limitations of Current System
========================================================

__*Thus* within current framework either weighted voting or PLR ensembling may only be performed with on analytic rubrics with positive/negtive coded bins__

These limits are *not* tied to the algorithms, but to the implementation

Testing: Weight Loss
========================================================

N=1175

Cross Validation Kappa Values
```{r,echo=FALSE}

Human <- c(385,10,99,478,10,219)
Simple <- c(0.955,0.181,0.387,0.695,0,0.857)
Weighted <- c(0.957,0.459,0.512,0.707,0,0.880)
PLR <- c(0.956,-0.002,0.621,0.733,0,0.889)
PLR2 <- c(0.956,0.000,0.586,0.727,0,0.886)

outDF <- data.frame(Human,Simple,Weighted,PLR,PLR2)
colnames(outDF) <- c("Human","Simple","Weighted","PLR L2","PLR L1")
kable(outDF)
```

Testing: Root Cell
=========================================================

N=677
Cross Validation Kappa Values
```{r,echo=FALSE}

Human <- c(175,127,69,139,110)
Simple <- c(0.795,0.812,0.738,0.878,0.580)
Weighted <- c(0.827,0.838,0.755,0.908,0.608)
PLR <- c(0.809,0.828,0.681,0.895,0.610)
PLR2 <-c(0.805,0.803,0.626,0.884,0.606)

outDF <- data.frame(Human,Simple,Weighted,PLR,PLR2)
colnames(outDF) <- c("Human","Simple","Weighted","PLR L2","PLR L1")
kable(outDF)

```



Testing: Grape
========================================================

N=317

Cross Validation Kappa Values
```{r,echo=FALSE}
Human <- c(161,56,28,62,67)
Simple <- c(0.861,0.712,0.364,0.562,0.630)
Weighted <- c(0.905,0.813,0.509,0.671,0.694)
PLR <- c(0.905,0.814,0.680,0.774,0.740)
PLR2 <-c(0.912,0.812,0.595,0.791,0.800)

outDF <- data.frame(Human,Simple,Weighted,PLR,PLR2)
colnames(outDF) <- c("Human","Simple","Weighted","PLR L2","PLR L1")
kable(outDF)

```

Testing: Non-coding Mutation
=========================================================

N=301
Cross Validation Kappa Values
```{r,echo=FALSE}

Human <- c(224,183,35,45,38,55,38)
Simple <- c(0.729,0.818,0.734,0.427,0.596,0.835,0.422)
Weighted <- c(0.727,0.795,0.779,0.531,0.652,0.861,0.475)
PLR <- c(0.706,0.768,0.755,0.489,0.525,0.824,0.300)
PLR2 <-c(0.693,0.762,0.800,0.493,0.583,0.794,0.208)

outDF <- data.frame(Human,Simple,Weighted,PLR,PLR2)
colnames(outDF) <- c("Human","Simple","Weighted","PLR L2","PLR L1")
kable(outDF)

```


Preliminary Results
==========================================================

__Leveraging prediction $\Longrightarrow$ higher performance models__

 - **Probability Weighted Voting preferred** for under sampled feature space; more data is better
 - **PLR preferred** well sampled feature space; identifying best predictors better
 - No clear preferred PLR penalty structure

